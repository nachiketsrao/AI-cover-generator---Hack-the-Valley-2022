{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "30920e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\codenacho\\anaconda3\\lib\\site-packages (2.25.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\codenacho\\anaconda3\\lib\\site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\codenacho\\anaconda3\\lib\\site-packages (from requests) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\codenacho\\anaconda3\\lib\\site-packages (from requests) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\codenacho\\anaconda3\\lib\\site-packages (from requests) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#%pip install SpeechRecognition // use this command with the % to pip install a project\n",
    "# TODO:\n",
    "'''\n",
    "The only problem with SpeechRecognition is that if the audio is too long, the request times out.\n",
    "Fix this.\n",
    "Don't forget citations!!\n",
    "'''\n",
    "#%pip install icrawler.examples\n",
    "#%pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "396cc782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting audio transcripts into text ...\n",
      "beauty queen of only 18 she had some trouble with her\n"
     ]
    }
   ],
   "source": [
    "#import library\n",
    "import speech_recognition as sr  # pip install req: SpeechRecognition\n",
    "\n",
    "# Initialize recognizer class (for recognizing the speech)\n",
    "r = sr.Recognizer()\n",
    "\n",
    "# Reading Audio file as source\n",
    "# listening the audio file and store in audio_text variable\n",
    "\n",
    "with sr.AudioFile('maroon1_10.wav') as source:\n",
    "    \n",
    "    audio_text = r.listen(source)\n",
    "    \n",
    "# recoginize_() method will throw a request error if the API is unreachable, hence using exception handling\n",
    "    #try:\n",
    "        # using google speech recognition\n",
    "    text = r.recognize_google(audio_text)\n",
    "    print('Converting audio transcripts into text ...')\n",
    "    print(text)\n",
    "    #except:\n",
    "        #print('Sorry.. run again...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3782fa9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all the words are:  ['beauty', 'queen', 'of', 'only', '18', 'she', 'had', 'some', 'trouble', 'with', 'her']\n",
      "number of words is:  11\n",
      "all the sentences are:  ['beauty queen of only 18 she had some trouble with her']\n",
      "number of sentences is:  1\n"
     ]
    }
   ],
   "source": [
    "# FINDING 5 IMPORTANT WORDS FROM LYRICS:\n",
    "# https://www.analyticsvidhya.com/blog/2020/11/words-that-matter-a-simple-guide-to-keyword-extraction-in-python/\n",
    "# I ran  python -m nltk.downloader stopwords in local repo\n",
    "# stopwords stored in : C:\\Users\\CodeNacho\\AppData\\Roaming\\nltk_data\n",
    "from nltk import tokenize\n",
    "from operator import itemgetter\n",
    "import math\n",
    "\n",
    "# we will be working on the lyrics stored in 'text'\n",
    "\n",
    "# we remove stopwords:\n",
    "import nltk\n",
    "#from nltk.corpus import stopwords\n",
    "#from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "total_words= nltk.word_tokenize(text)\n",
    "total_word_length= len(total_words)\n",
    "print(\"all the words are: \",total_words)\n",
    "print(\"number of words is: \",total_word_length)\n",
    "\n",
    "# nltk.download('all')\n",
    "total_sentences = tokenize.sent_tokenize(text)\n",
    "total_sent_len = len(total_sentences)\n",
    "print(\"all the sentences are: \",total_sentences)\n",
    "print(\"number of sentences is: \",total_sent_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dcf80023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'beauty': 0.09090909090909091, 'queen': 0.09090909090909091, 'trouble': 0.09090909090909091}\n"
     ]
    }
   ],
   "source": [
    "tf_score = {}\n",
    "for each_word in total_words:\n",
    "    each_word = each_word.replace('.','')\n",
    "    if each_word not in stop_words and each_word.isalpha(): # also excluding words that are numbers\n",
    "        if each_word in tf_score:\n",
    "            tf_score[each_word] += 1\n",
    "        else:\n",
    "            tf_score[each_word] = 1\n",
    "\n",
    "# TODO: exclude words that are not alphabets?\n",
    "# Dividing by total_word_length for each dictionary element\n",
    "tf_score.update((x, y/int(total_word_length)) for x, y in tf_score.items())\n",
    "print(tf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7cdb5e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sent(word, sentences): \n",
    "    final = [all([w in x for w in word]) for x in sentences] \n",
    "    sent_len = [sentences[i] for i in range(0, len(final)) if final[i]]\n",
    "    return int(len(sent_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0b9e5f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nidf_score = {}\\nfor each_word in total_words:\\n    each_word = each_word.replace('.','')\\n    if each_word not in stop_words:\\n        if each_word in idf_score:\\n            idf_score[each_word] = check_sent(each_word, total_sentences)\\n        else:\\n            idf_score[each_word] = 1\\n\\n# Performing a log and divide\\nidf_score.update((x, math.log(int(total_sent_len)/y)) for x, y in idf_score.items())\\n\\nprint(idf_score)\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: BIG PROBLEM, if the words don't occur enough times, the IDF is just 0 - this can break things\n",
    "# Since the text is short (as the speech recognizer only works with short audio files), don't use IDF now\n",
    "'''\n",
    "idf_score = {}\n",
    "for each_word in total_words:\n",
    "    each_word = each_word.replace('.','')\n",
    "    if each_word not in stop_words:\n",
    "        if each_word in idf_score:\n",
    "            idf_score[each_word] = check_sent(each_word, total_sentences)\n",
    "        else:\n",
    "            idf_score[each_word] = 1\n",
    "\n",
    "# Performing a log and divide\n",
    "idf_score.update((x, math.log(int(total_sent_len)/y)) for x, y in idf_score.items())\n",
    "\n",
    "print(idf_score)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98f7fefc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntf_idf_score = {key: tf_score[key] * idf_score.get(key, 0) for key in tf_score.keys()}\\nprint(tf_idf_score)\\ndef get_top_n(dict_elem, n):\\n    result = dict(sorted(dict_elem.items(), key = itemgetter(1), reverse = True)[:n]) \\n    return result\\nprint(get_top_n(tf_idf_score, 5)) # get the top 5 significant words\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN THIS ONLY WHEN BOTH TF AND IDF ARE AVAILABLE:\n",
    "'''\n",
    "tf_idf_score = {key: tf_score[key] * idf_score.get(key, 0) for key in tf_score.keys()}\n",
    "print(tf_idf_score)\n",
    "def get_top_n(dict_elem, n):\n",
    "    result = dict(sorted(dict_elem.items(), key = itemgetter(1), reverse = True)[:n]) \n",
    "    return result\n",
    "print(get_top_n(tf_idf_score, 5)) # get the top 5 significant words\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "033fe754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'beauty': 0.09090909090909091, 'queen': 0.09090909090909091, 'trouble': 0.09090909090909091}\n",
      "The keyword produced is:  beauty queen trouble \n"
     ]
    }
   ],
   "source": [
    "# USING ONLY TF (AS IDF MAY YIELD JUST 0 AND SCREW UP RESULTS)\n",
    "def get_top_n(dict_elem, n):\n",
    "    result = dict(sorted(dict_elem.items(), key = itemgetter(1), reverse = True)[:n]) \n",
    "    return result\n",
    "print(get_top_n(tf_score, 3)) # gets the top 3 words from lyrics (using onyl TF_SCORE)\n",
    "\n",
    "# making a custom keyword for image selection:\n",
    "top_results = get_top_n(tf_score, 3)\n",
    "keyword_final=\"\"\n",
    "for key in top_results:\n",
    "    keyword_final+=(key+\" \")\n",
    "keyword_final.strip()\n",
    "print(\"The keyword produced is: \", keyword_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "053cbab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET AN IMAGE FROM GOOGLE CLOSE TO THE KEYWORDS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad782a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-15 06:36:00,937 - INFO - icrawler.crawler - start crawling...\n",
      "2022-10-15 06:36:00,938 - INFO - icrawler.crawler - starting 1 feeder threads...\n",
      "2022-10-15 06:36:00,941 - INFO - feeder - thread feeder-001 exit\n",
      "2022-10-15 06:36:00,943 - INFO - icrawler.crawler - starting 1 parser threads...\n",
      "2022-10-15 06:36:00,949 - INFO - icrawler.crawler - starting 1 downloader threads...\n",
      "2022-10-15 06:36:01,600 - INFO - parser - parsing result page https://www.google.com/search?q=beauty+queen+trouble+&ijn=0&start=0&tbs=&tbm=isch\n",
      "2022-10-15 06:36:01,668 - INFO - downloader - skip downloading file 000001.jpg\n",
      "2022-10-15 06:36:01,673 - INFO - downloader - skip downloading file 000002.jpg\n",
      "2022-10-15 06:36:01,674 - INFO - downloader - skip downloading file 000003.jpg\n",
      "2022-10-15 06:36:01,675 - INFO - downloader - skip downloading file 000004.jpg\n",
      "2022-10-15 06:36:01,677 - INFO - downloader - skip downloading file 000005.jpg\n",
      "2022-10-15 06:36:01,678 - INFO - downloader - skip downloading file 000006.jpg\n",
      "2022-10-15 06:36:01,680 - INFO - downloader - skip downloading file 000007.jpg\n",
      "2022-10-15 06:36:01,682 - INFO - downloader - skip downloading file 000008.jpg\n",
      "2022-10-15 06:36:01,683 - INFO - downloader - skip downloading file 000009.jpg\n",
      "2022-10-15 06:36:01,685 - INFO - downloader - skip downloading file 000010.jpg\n",
      "2022-10-15 06:36:02,265 - INFO - downloader - downloaded images reach max num, thread downloader-001 is ready to exit\n",
      "2022-10-15 06:36:02,267 - INFO - downloader - thread downloader-001 exit\n",
      "2022-10-15 06:36:02,977 - INFO - icrawler.crawler - Crawling task done!\n",
      "2022-10-15 06:36:03,697 - INFO - parser - downloaded image reached max num, thread parser-001 is ready to exit\n",
      "2022-10-15 06:36:03,700 - INFO - parser - thread parser-001 exit\n"
     ]
    }
   ],
   "source": [
    "# link for help: https://snyk.io/advisor/python/icrawler/functions/icrawler.builtin.GoogleImageCrawler\n",
    "from icrawler.builtin import GoogleImageCrawler\n",
    "\n",
    "google_crawler = GoogleImageCrawler(storage={'root_dir': 'song-images'}) # TODO: make the root-dir name\n",
    "    # based on the name of the song. so that this doesn't need to be hardcoded\n",
    "google_crawler.crawl(keyword=keyword_final, max_num=5)\n",
    "\n",
    "#TODO: display all the images downloaded to give developer perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a602846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WOMBO!:\n",
    "# link for help: https://wombo.gitbook.io/dream-docs/quick-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9eb33613",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To authenticate request with WOMBO API:\n",
    "# generate API key using dashboard\n",
    "HEADERS = {        \n",
    "    'Authorization': 'bearer {oypnH5lBpuAtG5nezljBBFVnSqXaKpIH}',        \n",
    "    'Content-Type': 'application/json'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0e894307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def send_task_to_dream_api(style_id, prompt, target_img_path=None):\n",
    "    \"\"\"\n",
    "    Send requests to the dream API.\n",
    "    prompt is the text prompt.\n",
    "    style_id is which style to use (a mapping of ids to names is in the docs).\n",
    "    target_img_path is an optional path to an image to influence the generation.\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1) make a POST request to https://api.luan.tools/api/tasks/\n",
    "    post_payload = json.dumps({\n",
    "        \"use_target_image\": bool(\"./song-images/00003\") # hard coded value of image file\n",
    "        #TODO: change hardcode in above line\n",
    "    })\n",
    "    post_response = requests.request(\n",
    "        \"POST\", BASE_URL, headers=HEADERS, data=post_payload)\n",
    "    \n",
    "    # upload the target image to the url provided in the response from the previous POST request.\n",
    "    if target_img_path:\n",
    "        target_image_url = post_response.json()[\"target_image_url\"]\n",
    "        with open(target_img_path, 'rb') as f:\n",
    "            fields = target_image_url[\"fields\"]\n",
    "            fields [\"file\"] = f.read()\n",
    "            requests.request(\"POST\", url=target_image_url[\"url\"], files=fields)\n",
    "            \n",
    "    # Step 3) make a PUT request to https://api.luan.tools/api/tasks/{task_id}\n",
    "    # where task id is provided in the response from the request in Step 1.\n",
    "    task_id = post_response.json()['id']\n",
    "    task_id_url = f\"{BASE_URL}{task_id}\"\n",
    "    put_payload = json.dumps({\n",
    "        \"input_spec\": {\n",
    "            \"style\": style_id,\n",
    "            \"prompt\": prompt,\n",
    "            \"target_image_weight\": 0.1,\n",
    "            \"width\": 960,\n",
    "            \"height\": 1560\n",
    "    }})\n",
    "    requests.request(\n",
    "        \"PUT\", task_id_url, headers=HEADERS, data=put_payload)\n",
    "    \n",
    "    # Step 4) Keep polling for images until the generation completes\n",
    "    while True:\n",
    "        response_json = requests.request(\n",
    "            \"GET\", task_id_url, headers=HEADERS).json()\n",
    "\n",
    "        state = response_json[\"state\"]\n",
    "\n",
    "        if state == \"completed\":\n",
    "            r = requests.request(\n",
    "                \"GET\", response_json[\"result\"])\n",
    "            with open(\"image.jpg\", \"wb\") as image_file:\n",
    "                image_file.write(r.content)\n",
    "            print(\"image saved successfully :)\")\n",
    "            break\n",
    "\n",
    "        elif state ==\"failed\":\n",
    "            print(\"generation failed :(\")\n",
    "            break\n",
    "\n",
    "        time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e4879d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling the function in the previous cell:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a70cb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
