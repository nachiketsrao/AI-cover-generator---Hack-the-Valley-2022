{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30920e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement icrawler.examples\n",
      "ERROR: No matching distribution found for icrawler.examples\n"
     ]
    }
   ],
   "source": [
    "#%pip install SpeechRecognition // use this command with the % to pip install a project\n",
    "# TODO:\n",
    "'''\n",
    "The only problem with SpeechRecognition is that if the audio is too long, the request times out.\n",
    "Fix this.\n",
    "'''\n",
    "#%pip install icrawler.examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "396cc782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting audio transcripts into text ...\n",
      "beauty queen of only 18 she had some trouble with her\n"
     ]
    }
   ],
   "source": [
    "#import library\n",
    "import speech_recognition as sr  # pip install req: SpeechRecognition\n",
    "\n",
    "# Initialize recognizer class (for recognizing the speech)\n",
    "r = sr.Recognizer()\n",
    "\n",
    "# Reading Audio file as source\n",
    "# listening the audio file and store in audio_text variable\n",
    "\n",
    "with sr.AudioFile('maroon1_10.wav') as source:\n",
    "    \n",
    "    audio_text = r.listen(source)\n",
    "    \n",
    "# recoginize_() method will throw a request error if the API is unreachable, hence using exception handling\n",
    "    #try:\n",
    "        # using google speech recognition\n",
    "    text = r.recognize_google(audio_text)\n",
    "    print('Converting audio transcripts into text ...')\n",
    "    print(text)\n",
    "    #except:\n",
    "        #print('Sorry.. run again...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3782fa9c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stopwords' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-b040bf732772>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#from nltk.corpus import stopwords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m#from nltk.tokenize import word_tokenize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mstop_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'english'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stopwords' is not defined"
     ]
    }
   ],
   "source": [
    "# FINDING 5 IMPORTANT WORDS FROM LYRICS:\n",
    "# https://www.analyticsvidhya.com/blog/2020/11/words-that-matter-a-simple-guide-to-keyword-extraction-in-python/\n",
    "# I ran  python -m nltk.downloader stopwords in local repo\n",
    "# stopwords stored in : C:\\Users\\CodeNacho\\AppData\\Roaming\\nltk_data\n",
    "from nltk import tokenize\n",
    "from operator import itemgetter\n",
    "import math\n",
    "\n",
    "# we will be working on the lyrics stored in 'text'\n",
    "\n",
    "# we remove stopwords:\n",
    "import nltk\n",
    "#from nltk.corpus import stopwords\n",
    "#from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "total_words= nltk.word_tokenize(text)\n",
    "total_word_length= len(words)\n",
    "print(\"all the words are: \",total_words)\n",
    "print(\"number of words is: \",total_word_length)\n",
    "\n",
    "# nltk.download('all')\n",
    "total_sentences = tokenize.sent_tokenize(text)\n",
    "total_sent_len = len(total_sentences)\n",
    "print(\"all the sentences are: \",total_sentences)\n",
    "print(\"number of sentences is: \",total_sent_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "095fa368",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'total_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-029c6eb0efde>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtf_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0meach_word\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0meach_word\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meach_word\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0meach_word\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstop_words\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0meach_word\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misalpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# also excluding words that are numbers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0meach_word\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtf_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'total_words' is not defined"
     ]
    }
   ],
   "source": [
    "tf_score = {}\n",
    "for each_word in total_words:\n",
    "    each_word = each_word.replace('.','')\n",
    "    if each_word not in stop_words and each_word.isalpha(): # also excluding words that are numbers\n",
    "        if each_word in tf_score:\n",
    "            tf_score[each_word] += 1\n",
    "        else:\n",
    "            tf_score[each_word] = 1\n",
    "\n",
    "# TODO: exclude words that are not alphabets?\n",
    "# Dividing by total_word_length for each dictionary element\n",
    "tf_score.update((x, y/int(total_word_length)) for x, y in tf_score.items())\n",
    "print(tf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f2081b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sent(word, sentences): \n",
    "    final = [all([w in x for w in word]) for x in sentences] \n",
    "    sent_len = [sentences[i] for i in range(0, len(final)) if final[i]]\n",
    "    return int(len(sent_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "774d2a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nidf_score = {}\\nfor each_word in total_words:\\n    each_word = each_word.replace('.','')\\n    if each_word not in stop_words:\\n        if each_word in idf_score:\\n            idf_score[each_word] = check_sent(each_word, total_sentences)\\n        else:\\n            idf_score[each_word] = 1\\n\\n# Performing a log and divide\\nidf_score.update((x, math.log(int(total_sent_len)/y)) for x, y in idf_score.items())\\n\\nprint(idf_score)\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: BIG PROBLEM, if the words don't occur enough times, the IDF is just 0 - this can break things\n",
    "# Since the text is short (as the speech recognizer only works with short audio files), don't use IDF now\n",
    "'''\n",
    "idf_score = {}\n",
    "for each_word in total_words:\n",
    "    each_word = each_word.replace('.','')\n",
    "    if each_word not in stop_words:\n",
    "        if each_word in idf_score:\n",
    "            idf_score[each_word] = check_sent(each_word, total_sentences)\n",
    "        else:\n",
    "            idf_score[each_word] = 1\n",
    "\n",
    "# Performing a log and divide\n",
    "idf_score.update((x, math.log(int(total_sent_len)/y)) for x, y in idf_score.items())\n",
    "\n",
    "print(idf_score)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ede3d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntf_idf_score = {key: tf_score[key] * idf_score.get(key, 0) for key in tf_score.keys()}\\nprint(tf_idf_score)\\ndef get_top_n(dict_elem, n):\\n    result = dict(sorted(dict_elem.items(), key = itemgetter(1), reverse = True)[:n]) \\n    return result\\nprint(get_top_n(tf_idf_score, 5)) # get the top 5 significant words\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN THIS ONLY WHEN BOTH TF AND IDF ARE AVAILABLE:\n",
    "'''\n",
    "tf_idf_score = {key: tf_score[key] * idf_score.get(key, 0) for key in tf_score.keys()}\n",
    "print(tf_idf_score)\n",
    "def get_top_n(dict_elem, n):\n",
    "    result = dict(sorted(dict_elem.items(), key = itemgetter(1), reverse = True)[:n]) \n",
    "    return result\n",
    "print(get_top_n(tf_idf_score, 5)) # get the top 5 significant words\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26fb8163",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-f701c1aa4bd1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict_elem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitemgetter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_top_n\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# gets the top 3 words from lyrics (using onyl TF_SCORE)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# making a custom keyword for image selection:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf_score' is not defined"
     ]
    }
   ],
   "source": [
    "# USING ONLY TF (AS IDF MAY YIELD JUST 0 AND SCREW UP RESULTS)\n",
    "def get_top_n(dict_elem, n):\n",
    "    result = dict(sorted(dict_elem.items(), key = itemgetter(1), reverse = True)[:n]) \n",
    "    return result\n",
    "print(get_top_n(tf_score, 3)) # gets the top 3 words from lyrics (using onyl TF_SCORE)\n",
    "\n",
    "# making a custom keyword for image selection:\n",
    "top_results = get_top_n(tf_score, 3)\n",
    "keyword_final=\"\"\n",
    "for key in top_results:\n",
    "    keyword_final+=(key+\" \")\n",
    "print(\"The keyword produced is: \", keyword_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d8407590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET AN IMAGE FROM GOOGLE CLOSE TO THE KEYWORDS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bfe33a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-15 06:15:12,718 - INFO - icrawler.crawler - start crawling...\n",
      "2022-10-15 06:15:12,719 - INFO - icrawler.crawler - starting 1 feeder threads...\n",
      "2022-10-15 06:15:12,721 - INFO - feeder - thread feeder-001 exit\n",
      "2022-10-15 06:15:12,723 - INFO - icrawler.crawler - starting 1 parser threads...\n",
      "2022-10-15 06:15:12,727 - INFO - icrawler.crawler - starting 1 downloader threads...\n",
      "2022-10-15 06:15:13,338 - INFO - parser - parsing result page https://www.google.com/search?q=cat&ijn=0&start=0&tbs=&tbm=isch\n",
      "2022-10-15 06:15:14,155 - INFO - downloader - image #1\thttps://i.natgeofe.com/n/548467d8-c5f1-4551-9f58-6817a8d2c45e/NationalGeographic_2572187_3x2.jpg\n",
      "2022-10-15 06:15:14,454 - ERROR - downloader - Response status code 404, file https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Cat03.jpg\n",
      "2022-10-15 06:15:15,183 - INFO - downloader - image #2\thttps://upload.wikimedia.org/wikipedia/commons/0/0b/Cat_poster_1.jpg\n",
      "2022-10-15 06:15:15,390 - INFO - downloader - image #3\thttps://www.humanesociety.org/sites/default/files/styles/1240x698/public/2020-07/kitten-510651.jpg\n",
      "2022-10-15 06:15:15,521 - ERROR - downloader - Response status code 404, file https://upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Cat_November_2010-1a.jpg\n",
      "2022-10-15 06:15:15,604 - INFO - downloader - image #4\thttps://cdn.britannica.com/39/7139-050-A88818BB/Himalayan-chocolate-point.jpg\n",
      "2022-10-15 06:15:15,692 - INFO - downloader - image #5\thttps://www.rd.com/wp-content/uploads/2021/01/GettyImages-1175550351.jpg\n",
      "2022-10-15 06:15:15,712 - INFO - downloader - image #6\thttps://cdn.britannica.com/91/181391-050-1DA18304/cat-toes-paw-number-paws-tiger-tabby.jpg\n",
      "2022-10-15 06:15:15,878 - INFO - downloader - image #7\thttps://spca.bc.ca/wp-content/uploads/white-cat-on-plaid-pillow-825x549.jpg\n",
      "2022-10-15 06:15:16,170 - INFO - downloader - image #8\thttps://www.allaboutcats.ca/wp-content/uploads/sites/235/2022/03/17-1.png\n",
      "2022-10-15 06:15:17,178 - INFO - downloader - image #9\thttps://icatcare.org/app/uploads/2018/07/Thinking-of-getting-a-cat.png\n",
      "2022-10-15 06:15:17,287 - ERROR - downloader - Response status code 401, file https://i.guim.co.uk/img/media/26392d05302e02f7bf4eb143bb84c8097d09144b/446_167_3683_2210/master/3683.jpg\n",
      "2022-10-15 06:15:17,890 - INFO - downloader - image #10\thttps://i.cbc.ca/1.5256404.1566499707!/fileImage/httpImage/image.jpg\n",
      "2022-10-15 06:15:17,921 - INFO - downloader - downloaded images reach max num, thread downloader-001 is ready to exit\n",
      "2022-10-15 06:15:17,923 - INFO - downloader - thread downloader-001 exit\n",
      "2022-10-15 06:15:18,820 - INFO - icrawler.crawler - Crawling task done!\n",
      "2022-10-15 06:15:18,899 - INFO - parser - downloaded image reached max num, thread parser-001 is ready to exit\n",
      "2022-10-15 06:15:18,901 - INFO - parser - thread parser-001 exit\n"
     ]
    }
   ],
   "source": [
    "from icrawler.builtin import GoogleImageCrawler\n",
    "\n",
    "google_crawler = GoogleImageCrawler(storage={'root_dir': 'song-images'}) # TODO: make the root-dir name\n",
    "    # based on the name of the song. so that this doesn't need to be hardcoded\n",
    "google_crawler.crawl(keyword=keyword_final, max_num=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35059709",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
