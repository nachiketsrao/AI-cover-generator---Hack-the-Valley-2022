{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30920e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
      "Collecting icrawler\n",
      "  Downloading icrawler-0.6.6-py2.py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in /opt/homebrew/lib/python3.9/site-packages (from icrawler) (4.11.1)\n",
      "Collecting lxml\n",
      "  Downloading lxml-4.9.1.tar.gz (3.4 MB)\n",
      "     |████████████████████████████████| 3.4 MB 15.1 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /opt/homebrew/lib/python3.9/site-packages (from icrawler) (1.16.0)\n",
      "Requirement already satisfied: Pillow in /opt/homebrew/lib/python3.9/site-packages (from icrawler) (9.2.0)\n",
      "Requirement already satisfied: requests>=2.9.1 in /opt/homebrew/lib/python3.9/site-packages (from icrawler) (2.28.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/homebrew/lib/python3.9/site-packages (from beautifulsoup4>=4.4.1->icrawler) (2.3.2.post1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.9/site-packages (from requests>=2.9.1->icrawler) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.9/site-packages (from requests>=2.9.1->icrawler) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/homebrew/lib/python3.9/site-packages (from requests>=2.9.1->icrawler) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/lib/python3.9/site-packages (from requests>=2.9.1->icrawler) (1.26.12)\n",
      "Building wheels for collected packages: lxml\n",
      "  Building wheel for lxml (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lxml: filename=lxml-4.9.1-cp39-cp39-macosx_12_0_arm64.whl size=1513187 sha256=9177f18c4b664dbaaa0eae5a2a50dae85f535a93958e094fbfdfdd7fadaad375\n",
      "  Stored in directory: /Users/hassanjamil/Library/Caches/pip/wheels/bc/40/07/57dfeee521e18239f57d187948850364c1818be877c9acdf5e\n",
      "Successfully built lxml\n",
      "Installing collected packages: lxml, icrawler\n",
      "\u001b[33m  DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
      "Successfully installed icrawler-0.6.6 lxml-4.9.1\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/opt/homebrew/opt/python@3.9/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#%pip install SpeechRecognition // use this command with the % to pip install a project\n",
    "# TODO:\n",
    "'''\n",
    "The only problem with SpeechRecognition is that if the audio is too long, the request times out.\n",
    "Fix this.\n",
    "Don't forget citations!!\n",
    "'''\n",
    "#%pip install icrawler.examples\n",
    "#%pip install requests\n",
    "#%pip install nltk\n",
    "#%pip install icrawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c7c584",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Copyright 2019 Trevor van Hoof and Jan Pijpers.\n",
    "##  Licensed under the Apache License, Version 2.0\n",
    "##  Downloaded from https://janpijpers.com or https://gumroad.com/janpijpers\n",
    "##  See the license file attached or on https://www.janpijpers.com/script-licenses/\n",
    "from scipy.io import wavfile\n",
    "\n",
    "def trim_wav( originalWavPath, newWavPath , start, end ):\n",
    "    '''\n",
    "    :param originalWavPath: the path to the source wav file\n",
    "    :param newWavPath: output wav file * can be same path as original\n",
    "    :param start: time in seconds\n",
    "    :param end: time in seconds\n",
    "    :return:\n",
    "    '''\n",
    "    sampleRate, waveData = wavfile.read( originalWavPath )\n",
    "    waveData.size\n",
    "    startSample = int( start * sampleRate )\n",
    "    endSample = int( end * sampleRate )\n",
    "    wavfile.write( newWavPath, sampleRate, waveData[startSample:endSample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cddf23",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "FLAC conversion utility not available - consider installing the FLAC command line application by running `apt-get install flac` or your operating system's equivalent",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn [12], line 31\u001b[0m\n",
      "\u001b[1;32m     26\u001b[0m audio_text \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mlisten(source)\n",
      "\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# recoginize_() method will throw a request error if the API is unreachable, hence using exception handling\u001b[39;00m\n",
      "\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m#try:\u001b[39;00m\n",
      "\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# using google speech recognition\u001b[39;00m\n",
      "\u001b[0;32m---> 31\u001b[0m text \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize_google\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_text\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConverting audio transcripts into text ...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m#except:\u001b[39;00m\n",
      "\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m#print('Sorry.. run again...')\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/speech_recognition/__init__.py:826\u001b[0m, in \u001b[0;36mRecognizer.recognize_google\u001b[0;34m(self, audio_data, key, language, show_all)\u001b[0m\n",
      "\u001b[1;32m    823\u001b[0m \u001b[39massert\u001b[39;00m key \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mstr\u001b[39m), \u001b[39m\"\u001b[39m\u001b[39m``key`` must be ``None`` or a string\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;32m    824\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(language, \u001b[39mstr\u001b[39m), \u001b[39m\"\u001b[39m\u001b[39m``language`` must be a string\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;32m--> 826\u001b[0m flac_data \u001b[39m=\u001b[39m audio_data\u001b[39m.\u001b[39;49mget_flac_data(\n",
      "\u001b[1;32m    827\u001b[0m     convert_rate\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m audio_data\u001b[39m.\u001b[39;49msample_rate \u001b[39m>\u001b[39;49m\u001b[39m=\u001b[39;49m \u001b[39m8000\u001b[39;49m \u001b[39melse\u001b[39;49;00m \u001b[39m8000\u001b[39;49m,  \u001b[39m# audio samples must be at least 8 kHz\u001b[39;49;00m\n",
      "\u001b[1;32m    828\u001b[0m     convert_width\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m  \u001b[39m# audio samples must be 16-bit\u001b[39;49;00m\n",
      "\u001b[1;32m    829\u001b[0m )\n",
      "\u001b[1;32m    830\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m: key \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mAIzaSyBOti4mM-6x9WDnZIjIeyEU21OpBXqWBgw\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;32m    831\u001b[0m url \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhttp://www.google.com/speech-api/v2/recognize?\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(urlencode({\n",
      "\u001b[1;32m    832\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mclient\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mchromium\u001b[39m\u001b[39m\"\u001b[39m,\n",
      "\u001b[1;32m    833\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mlang\u001b[39m\u001b[39m\"\u001b[39m: language,\n",
      "\u001b[1;32m    834\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mkey\u001b[39m\u001b[39m\"\u001b[39m: key,\n",
      "\u001b[1;32m    835\u001b[0m }))\n",
      "\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/speech_recognition/__init__.py:445\u001b[0m, in \u001b[0;36mAudioData.get_flac_data\u001b[0;34m(self, convert_rate, convert_width)\u001b[0m\n",
      "\u001b[1;32m    443\u001b[0m \u001b[39m# run the FLAC converter with the WAV data to get the FLAC data\u001b[39;00m\n",
      "\u001b[1;32m    444\u001b[0m wav_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_wav_data(convert_rate, convert_width)\n",
      "\u001b[0;32m--> 445\u001b[0m flac_converter \u001b[39m=\u001b[39m get_flac_converter()\n",
      "\u001b[1;32m    446\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mname \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mnt\u001b[39m\u001b[39m\"\u001b[39m:  \u001b[39m# on Windows, specify that the process is to be started without showing a console window\u001b[39;00m\n",
      "\u001b[1;32m    447\u001b[0m     startup_info \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39mSTARTUPINFO()\n",
      "\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/speech_recognition/__init__.py:1196\u001b[0m, in \u001b[0;36mget_flac_converter\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m   1194\u001b[0m         flac_converter \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(base_path, \u001b[39m\"\u001b[39m\u001b[39mflac-linux-x86_64\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m   1195\u001b[0m     \u001b[39melse\u001b[39;00m:  \u001b[39m# no FLAC converter available\u001b[39;00m\n",
      "\u001b[0;32m-> 1196\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mFLAC conversion utility not available - consider installing the FLAC command line application by running `apt-get install flac` or your operating system\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms equivalent\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m   1198\u001b[0m \u001b[39m# mark FLAC converter as executable if possible\u001b[39;00m\n",
      "\u001b[1;32m   1199\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;32m   1200\u001b[0m     \u001b[39m# handle known issue when running on docker:\u001b[39;00m\n",
      "\u001b[1;32m   1201\u001b[0m     \u001b[39m# run executable right after chmod() may result in OSError \"Text file busy\"\u001b[39;00m\n",
      "\u001b[1;32m   1202\u001b[0m     \u001b[39m# fix: flush FS with sync\u001b[39;00m\n",
      "\n",
      "\u001b[0;31mOSError\u001b[0m: FLAC conversion utility not available - consider installing the FLAC command line application by running `apt-get install flac` or your operating system's equivalent"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr  # pip install req: SpeechRecognition\n",
    "\n",
    "# Initialize recognizer class (for recognizing the speech)\n",
    "r = sr.Recognizer()\n",
    "\n",
    "# Trimming info\n",
    "trimmed_length = 10 # how many seconds long each trimmed vid shouuld be\n",
    "wp = \"../all_the_wavs/maroon1.wav\"\n",
    "sampleRate, waveData = wavfile.read( wp )\n",
    "length = int(waveData.size / sampleRate) # length in seconds; waveData.size represents sampleRate * seconds\n",
    "\n",
    "# where all lyrics are accumatively stored\n",
    "text = \"\"\n",
    "\n",
    "for x in range(0,length,trimmed_length): # foreach \"chunk\" of vid\n",
    "    # extension handling\n",
    "    extension = str(int(x/10)) + \"_trimmed.wav\"\n",
    "    trimmed_name = wp.replace(\".wav\", extension)\n",
    "\n",
    "    # creating new chunk\n",
    "    trim_wav(wp, trimmed_name, x, x+trimmed_length)\n",
    "    \n",
    "    # Reading Audio file chunk as source\n",
    "    # listening the audio file and store in audio_text variable\n",
    "    with sr.AudioFile( trimmed_name ) as source:\n",
    "        audio_text = r.listen(source)\n",
    "        \n",
    "        # recoginize_() method will throw a request error if the API is unreachable, hence using exception handling\n",
    "        #try:\n",
    "            # using google speech recognition\n",
    "        text += r.recognize_google(audio_text)\n",
    "        print('Converting audio transcripts into text ...')\n",
    "        #except:\n",
    "            #print('Sorry.. run again...')\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3782fa9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all the words are:  ['beauty', 'queen', 'of', 'only', '18', 'she', 'had', 'some', 'trouble', 'with', 'her']\n",
      "number of words is:  11\n",
      "all the sentences are:  ['beauty queen of only 18 she had some trouble with her']\n",
      "number of sentences is:  1\n"
     ]
    }
   ],
   "source": [
    "# FINDING 5 IMPORTANT WORDS FROM LYRICS:\n",
    "# https://www.analyticsvidhya.com/blog/2020/11/words-that-matter-a-simple-guide-to-keyword-extraction-in-python/\n",
    "# I ran  python -m nltk.downloader stopwords in local repo\n",
    "# stopwords stored in : C:\\Users\\CodeNacho\\AppData\\Roaming\\nltk_data\n",
    "from nltk import tokenize\n",
    "from operator import itemgetter\n",
    "import math\n",
    "\n",
    "# we will be working on the lyrics stored in 'text'\n",
    "\n",
    "# we remove stopwords:\n",
    "import nltk\n",
    "#nltk.download('all')\n",
    "#from nltk.corpus import stopwords\n",
    "#from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "total_words= nltk.word_tokenize(text)\n",
    "total_word_length= len(total_words)\n",
    "print(\"all the words are: \",total_words)\n",
    "print(\"number of words is: \",total_word_length)\n",
    "\n",
    "# nltk.download('all')\n",
    "total_sentences = tokenize.sent_tokenize(text)\n",
    "total_sent_len = len(total_sentences)\n",
    "print(\"all the sentences are: \",total_sentences)\n",
    "print(\"number of sentences is: \",total_sent_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af0e7363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'beauty': 0.09090909090909091, 'queen': 0.09090909090909091, 'trouble': 0.09090909090909091}\n"
     ]
    }
   ],
   "source": [
    "tf_score = {}\n",
    "for each_word in total_words:\n",
    "    each_word = each_word.replace('.','')\n",
    "    if each_word not in stop_words and each_word.isalpha(): # also excluding words that are numbers\n",
    "        if each_word in tf_score:\n",
    "            tf_score[each_word] += 1\n",
    "        else:\n",
    "            tf_score[each_word] = 1\n",
    "\n",
    "# TODO: exclude words that are not alphabets?\n",
    "# Dividing by total_word_length for each dictionary element\n",
    "tf_score.update((x, y/int(total_word_length)) for x, y in tf_score.items())\n",
    "print(tf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54e6c88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sent(word, sentences): \n",
    "    final = [all([w in x for w in word]) for x in sentences] \n",
    "    sent_len = [sentences[i] for i in range(0, len(final)) if final[i]]\n",
    "    return int(len(sent_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "47a60a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nidf_score = {}\\nfor each_word in total_words:\\n    each_word = each_word.replace('.','')\\n    if each_word not in stop_words:\\n        if each_word in idf_score:\\n            idf_score[each_word] = check_sent(each_word, total_sentences)\\n        else:\\n            idf_score[each_word] = 1\\n\\n# Performing a log and divide\\nidf_score.update((x, math.log(int(total_sent_len)/y)) for x, y in idf_score.items())\\n\\nprint(idf_score)\\n\""
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: BIG PROBLEM, if the words don't occur enough times, the IDF is just 0 - this can break things\n",
    "# Since the text is short (as the speech recognizer only works with short audio files), don't use IDF now\n",
    "'''\n",
    "idf_score = {}\n",
    "for each_word in total_words:\n",
    "    each_word = each_word.replace('.','')\n",
    "    if each_word not in stop_words:\n",
    "        if each_word in idf_score:\n",
    "            idf_score[each_word] = check_sent(each_word, total_sentences)\n",
    "        else:\n",
    "            idf_score[each_word] = 1\n",
    "\n",
    "# Performing a log and divide\n",
    "idf_score.update((x, math.log(int(total_sent_len)/y)) for x, y in idf_score.items())\n",
    "\n",
    "print(idf_score)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ede8b05e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntf_idf_score = {key: tf_score[key] * idf_score.get(key, 0) for key in tf_score.keys()}\\nprint(tf_idf_score)\\ndef get_top_n(dict_elem, n):\\n    result = dict(sorted(dict_elem.items(), key = itemgetter(1), reverse = True)[:n]) \\n    return result\\nprint(get_top_n(tf_idf_score, 5)) # get the top 5 significant words\\n'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN THIS ONLY WHEN BOTH TF AND IDF ARE AVAILABLE:\n",
    "'''\n",
    "tf_idf_score = {key: tf_score[key] * idf_score.get(key, 0) for key in tf_score.keys()}\n",
    "print(tf_idf_score)\n",
    "def get_top_n(dict_elem, n):\n",
    "    result = dict(sorted(dict_elem.items(), key = itemgetter(1), reverse = True)[:n]) \n",
    "    return result\n",
    "print(get_top_n(tf_idf_score, 5)) # get the top 5 significant words\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f99f9087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'beauty': 0.09090909090909091, 'queen': 0.09090909090909091, 'trouble': 0.09090909090909091}\n",
      "The keyword produced is:  beauty queen trouble \n"
     ]
    }
   ],
   "source": [
    "# USING ONLY TF (AS IDF MAY YIELD JUST 0 AND SCREW UP RESULTS)\n",
    "def get_top_n(dict_elem, n):\n",
    "    result = dict(sorted(dict_elem.items(), key = itemgetter(1), reverse = True)[:n]) \n",
    "    return result\n",
    "print(get_top_n(tf_score, 3)) # gets the top 3 words from lyrics (using onyl TF_SCORE)\n",
    "\n",
    "# making a custom keyword for image selection:\n",
    "top_results = get_top_n(tf_score, 3)\n",
    "keyword_final=\"\"\n",
    "for key in top_results:\n",
    "    keyword_final+=(key+\" \")\n",
    "keyword_final.strip()\n",
    "print(\"The keyword produced is: \", keyword_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22bf7704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET AN IMAGE FROM GOOGLE CLOSE TO THE KEYWORDS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8962f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-15 18:07:04,917 - INFO - icrawler.crawler - start crawling...\n",
      "2022-10-15 18:07:04,917 - INFO - icrawler.crawler - starting 1 feeder threads...\n",
      "2022-10-15 18:07:04,918 - INFO - feeder - thread feeder-001 exit\n",
      "2022-10-15 18:07:04,919 - INFO - icrawler.crawler - starting 1 parser threads...\n",
      "2022-10-15 18:07:04,921 - INFO - icrawler.crawler - starting 1 downloader threads...\n",
      "2022-10-15 18:07:05,718 - INFO - parser - parsing result page https://www.google.com/search?q=beauty+queen+trouble+&ijn=0&start=0&tbs=&tbm=isch\n",
      "Exception in thread parser-001:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/lib/python3.9/site-packages/icrawler/parser.py\", line 104, in worker_exec\n",
      "    for task in self.parse(response, **kwargs):\n",
      "  File \"/opt/homebrew/lib/python3.9/site-packages/icrawler/builtin/google.py\", line 144, in parse\n",
      "    soup = BeautifulSoup(\n",
      "  File \"/opt/homebrew/lib/python3.9/site-packages/bs4/__init__.py\", line 248, in __init__\n",
      "    raise FeatureNotFound(\n",
      "bs4.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?\n",
      "2022-10-15 18:07:09,928 - INFO - downloader - no more download task for thread downloader-001\n",
      "2022-10-15 18:07:09,929 - INFO - downloader - thread downloader-001 exit\n",
      "2022-10-15 18:07:09,943 - INFO - icrawler.crawler - Crawling task done!\n"
     ]
    }
   ],
   "source": [
    "# link for help: https://snyk.io/advisor/python/icrawler/functions/icrawler.builtin.GoogleImageCrawler\n",
    "from icrawler.builtin import GoogleImageCrawler\n",
    "\n",
    "google_crawler = GoogleImageCrawler(storage={'root_dir': 'song-images'}) # TODO: make the root-dir name\n",
    "    # based on the name of the song. so that this doesn't need to be hardcoded\n",
    "google_crawler.crawl(keyword=keyword_final, max_num=5)\n",
    "\n",
    "#TODO: display all the images downloaded to give developer perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d738723e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WOMBO!:\n",
    "# link for help: https://wombo.gitbook.io/dream-docs/quick-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba0c6710",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To authenticate request with WOMBO API:\n",
    "# generate API key using dashboard\n",
    "HEADERS = {        \n",
    "    'Authorization': 'bearer PF92ODppTJPZbZr2h10XJx1LwRJGU7IW',        \n",
    "    'Content-Type': 'application/json'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ebbc48ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import requests\n",
    "BASE_URL = \"https://api.luan.tools/api/tasks/\"\n",
    "def send_task_to_dream_api(style_id, prompt, target_img_path=None):\n",
    "    \"\"\"\n",
    "    Send requests to the dream API.\n",
    "    prompt is the text prompt.\n",
    "    style_id is which style to use (a mapping of ids to names is in the docs).\n",
    "    target_img_path is an optional path to an image to influence the generation.\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1) make a POST request to https://api.luan.tools/api/tasks/\n",
    "    print(bool(target_img_path)) # debug\n",
    "    post_payload = json.dumps({\n",
    "        \"use_target_image\": bool(target_img_path)\n",
    "    })\n",
    "    post_response = requests.request(\n",
    "        \"POST\", BASE_URL, headers=HEADERS, data=post_payload)\n",
    "    print(post_response)\n",
    "    print(post_response.json())\n",
    "    \n",
    "    '''\n",
    "    # Step 2) skip this step if you're not sending a target image otherwise,\n",
    "    # upload the target image to the url provided in the response from the previous POST request.\n",
    "    if target_img_path:\n",
    "        target_image_url = post_response.json()[\"target_image_url\"]\n",
    "        with open(target_img_path, 'rb') as f:\n",
    "            fields = target_image_url[\"fields\"]\n",
    "            fields [\"file\"] = f.read()\n",
    "            requests.request(\"POST\", url=target_image_url[\"url\"], files=fields)\n",
    "'''\n",
    "    # Step 3) make a PUT request to https://api.luan.tools/api/tasks/{task_id}\n",
    "    # where task id is provided in the response from the request in Step 1.\n",
    "    task_id = post_response.json()['id']\n",
    "    task_id_url = f\"{BASE_URL}{task_id}\"\n",
    "    put_payload = json.dumps({\n",
    "        \"input_spec\": {\n",
    "            \"style\": style_id,\n",
    "            \"prompt\": prompt,\n",
    "            \"target_image_weight\": 0.1,\n",
    "            \"width\": 960,\n",
    "            \"height\": 1560\n",
    "    }})\n",
    "    requests.request(\n",
    "        \"PUT\", task_id_url, headers=HEADERS, data=put_payload)\n",
    "\n",
    "    # Step 4) Keep polling for images until the generation completes\n",
    "    while True:\n",
    "        response_json = requests.request(\n",
    "            \"GET\", task_id_url, headers=HEADERS).json()\n",
    "\n",
    "        state = response_json[\"state\"]\n",
    "\n",
    "        if state == \"completed\":\n",
    "            r = requests.request(\n",
    "                \"GET\", response_json[\"result\"])\n",
    "            with open(\"image.jpg\", \"wb\") as image_file:\n",
    "                image_file.write(r.content)\n",
    "            print(\"image saved successfully :)\")\n",
    "            break\n",
    "\n",
    "        elif state ==\"failed\":\n",
    "            print(\"generation failed :(\")\n",
    "            break\n",
    "\n",
    "        time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "42be15bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "<Response [200]>\n",
      "{'id': 'caff5efe-ff09-43c0-af90-01f7fe12d957', 'input_spec': None, 'state': 'input', 'photo_url_list': None, 'result': None, 'use_target_image': False, 'target_image_url': None, 'created_at': '2022-10-15T21:31:50.270896+00:00', 'updated_at': '2022-10-15T21:31:50.270902+00:00'}\n",
      "image saved successfully :)\n"
     ]
    }
   ],
   "source": [
    "# calling the function in the previous cell:\n",
    "#send_task_to_dream_api(7, keyword_final, \"./000003.jpg\")\n",
    "send_task_to_dream_api(7, keyword_final)\n",
    "#TODO: let the keyword be one word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9c2ca1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
